1. Загрузите заданный в индивидуальном задании набор данных с изображениями из Tensorflow Datasets с разбиением на обучающую, валидационную и тестовую выборки. Если при дальнейшей работе с данными возникнет нехватка вычислительных ресурсов, то разрешение изображений можно уменьшить.  

2. Оставьте в наборе изображения, указанных в индивидуальном задании, и визуализируйте несколько изображений. 

3. Постройте нейронные сети MLP, CNN и RNN для задачи многоклассовой классификации изображений (требования к архитектуре сетей указаны в индивидуальном задании), используя функцию потерь, указанную в индивидуальном задании. Подберите такие параметры, как функции активации, оптимизатор, начальная скорость обучения, размер мини-пакета и др. самостоятельно, обеспечивая обучение нейронных сетей. Обучайте нейронные сети с использованием валидационной выборки, сформированной в п. 1- Останавливайте обучение нейронных сетей в случае роста потерь на валидационной выборке на нескольких эпохах обучения подряд. Для каждой нейронной сети выведите количество потребовавшихся эпох обучения.  

4. Оцените качество многоклассовой классификации нейронными сетями MLP, CNN и RNN на тестовой выборке при помощи показателя качества, указанного в индивидуальном задании, и выведите архитектуру нейронной сети с лучшим качеством.  

5. Визуализируйте кривые обучения трех построенных моделей для показателя потерь на валидационной выборке на одном рисунке в зависимости от эпохи обучения, подписывая оси и рисунок и создавая легенду. Используйте для визуализации относительные потери (потери, деленные на начальные потери на первой эпохе). 

6. Визуализируйте кривые обучения трех построенных моделей для показателя доли верных ответов на валидационной выборке на одном рисунке в зависимости от эпохи обучения, подписывая оси и рисунок и создавая легенду. 

7. Используя модель нейронной сети с лучшей долей верных ответов на тестовой выборке, определите для каждого из классов два изображения в тестовой выборке, имеющие минимальную и максимальную вероятности классификации в правильный класс, и визуализируйте эти изображения. 
==========================================================================================


Вариант 15 

1. Набор данных oxford_iiit_pet с изменением разрешения до 60x96 

2. Классы с метками 11,21,31,32,33 

3. Требования к архитектуре сети MLP: 

Последовательный API с методом add() при создании 

Функция потерь: категориальная кросс-энтропия 

Кол-во скрытых слоев 6 

Кол-во нейронов 30 в первом скрытом слое, увеличивающееся на 15 с каждым последующим скрытым слоем 

Использование слоев с регуляризацией L1L2 

4. Требования к архитектуре сети CNN: 

Функциональный API при создании 

Функция потерь: разреженная категориальная кросс-энтропия 

Кол-во сверточных слоев 2 

Количество фильтров в сверточных слоях 32 

Размеры фильтра 3х3 

Использование слоев пакетной нормализации 

5. Требования к архитектуре сети RNN: 

Последовательный API со списком слоев при создании 

Функция потерь: категориальная кросс-энтропия 

Слой LSTM с 96 нейронами 

Использование слоев dropout 

6. Показатель качества многоклассовой классификации: 

минимальная точность классов, где точность (precision) класса равна доле правильных предсказаний для всех точек, относимых классификатором к этому классу. 
 